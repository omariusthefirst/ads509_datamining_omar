{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95952cac",
   "metadata": {},
   "source": [
    "# ADS 509 Module 1: APIs and Web Scraping\n",
    "#### Omar Elfeky\n",
    "\n",
    "This notebook has three parts. In the first part you will pull data from the Twitter API. In the second, you will scrape lyrics from AZLyrics.com. In the last part, you'll run code that verifies the completeness of your data pull. \n",
    "\n",
    "For this assignment you have chosen two musical artists who have at least 100,000 Twitter followers and 20 songs with lyrics on AZLyrics.com. In this part of the assignment we pull the some of the user information for the followers of your artist and store them in text files. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "069b7ae8",
   "metadata": {},
   "source": [
    "## General Assignment Instructions\n",
    "\n",
    "These instructions are included in every assignment, to remind you of the coding standards for the class. Feel free to delete this cell after reading it. \n",
    "\n",
    "One sign of mature code is conforming to a style guide. We recommend the [Google Python Style Guide](https://google.github.io/styleguide/pyguide.html). If you use a different style guide, please include a cell with a link. \n",
    "\n",
    "Your code should be relatively easy-to-read, sensibly commented, and clean. Writing code is a messy process, so please be sure to edit your final submission. Remove any cells that are not needed or parts of cells that contain unnecessary code. Remove inessential `import` statements and make sure that all such statements are moved into the designated cell. \n",
    "\n",
    "Make use of non-code cells for written commentary. These cells should be grammatical and clearly written. In some of these cells you will have questions to answer. The questions will be marked by a \"Q:\" and will have a corresponding \"A:\" spot for you. *Make sure to answer every question marked with a `Q:` for full credit.* \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c8969e",
   "metadata": {},
   "source": [
    "# Twitter API Pull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "185076b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for the twitter section\n",
    "import tweepy\n",
    "import os\n",
    "import datetime\n",
    "import re\n",
    "from pprint import pprint\n",
    "\n",
    "# for the lyrics scrape section\n",
    "import requests\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "from collections import defaultdict, Counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a47e2d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this cell for any import statements you add\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c21c86ec",
   "metadata": {},
   "source": [
    "We need bring in our API keys. Since API keys should be kept secret, we'll keep them in a file called `api_keys.py`. This file should be stored in the directory where you store this notebook. The example file is provided for you on Blackboard. The example has API keys that are _not_ functional, so you'll need to get Twitter credentials and replace the placeholder keys. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f01bdec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import api_keys\n",
    "from api_keys import api_key, api_key_secret, access_token, access_token_secret "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "461d8232",
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = tweepy.OAuthHandler(api_key,api_key_secret)\n",
    "auth.set_access_token(access_token,access_token_secret)\n",
    "\n",
    "api = tweepy.API(\n",
    "    auth,\n",
    "    wait_on_rate_limit=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cb294620",
   "metadata": {},
   "outputs": [
    {
     "ename": "Forbidden",
     "evalue": "403 Forbidden\n453 - You currently have Essential access which includes access to Twitter API v2 endpoints only. If you need access to this endpoint, youâ€™ll need to apply for Elevated access via the Developer Portal. You can learn more here: https://developer.twitter.com/en/docs/twitter-api/getting-started/about-twitter-api#v2-access-leve",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mForbidden\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-1ab14bb9443f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mpage\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtweepy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCursor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mapi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_follower_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpages\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mids\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tweepy\\cursor.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 86\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tweepy\\cursor.py\u001b[0m in \u001b[0;36mnext\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    108\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext_cursor\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_tweets\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlimit\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 110\u001b[1;33m         data, cursors = self.method(cursor=self.next_cursor,\n\u001b[0m\u001b[0;32m    111\u001b[0m                                     \u001b[1;33m*\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m                                     **self.kwargs)\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tweepy\\api.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[1;33m@\u001b[0m\u001b[0mfunctools\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwraps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpagination_mode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tweepy\\api.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     44\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'payload_list'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpayload_list\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'payload_type'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpayload_type\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpayload_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpayload_list\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpayload_type\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpayload_type\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tweepy\\api.py\u001b[0m in \u001b[0;36mget_follower_ids\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m   2112\u001b[0m         \u001b[0mhttps\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m//\u001b[0m\u001b[0mdeveloper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtwitter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcom\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0men\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mdocs\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mtwitter\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mapi\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mv1\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0maccounts\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;32mand\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0musers\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mfollow\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0msearch\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0musers\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mapi\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mreference\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mfollowers\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mids\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2113\u001b[0m         \"\"\"\n\u001b[1;32m-> 2114\u001b[1;33m         return self.request(\n\u001b[0m\u001b[0;32m   2115\u001b[0m             'GET', 'followers/ids', endpoint_parameters=(\n\u001b[0;32m   2116\u001b[0m                 \u001b[1;34m'user_id'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'screen_name'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'cursor'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'stringify_ids'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'count'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tweepy\\api.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, endpoint, endpoint_parameters, params, headers, json_payload, parser, payload_list, payload_type, post_data, files, require_auth, return_cursors, upload_api, use_cache, **kwargs)\u001b[0m\n\u001b[0;32m    257\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mUnauthorized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m403\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 259\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mForbidden\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    260\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m404\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mNotFound\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mForbidden\u001b[0m: 403 Forbidden\n453 - You currently have Essential access which includes access to Twitter API v2 endpoints only. If you need access to this endpoint, youâ€™ll need to apply for Elevated access via the Developer Portal. You can learn more here: https://developer.twitter.com/en/docs/twitter-api/getting-started/about-twitter-api#v2-access-leve"
     ]
    }
   ],
   "source": [
    "\n",
    "# get a list of followers for professor Chandler.\n",
    "handle = \"37chandler\"\n",
    "ids = []\n",
    "\n",
    "for page in tweepy.Cursor(api.get_follower_ids, screen_name=handle).pages():\n",
    "    ids.extend(page)\n",
    "    time.sleep(30)\n",
    "\n",
    "print(len(ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e0c251d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API Host api.twitter.com\n"
     ]
    },
    {
     "ename": "Forbidden",
     "evalue": "403 Forbidden\n453 - You currently have Essential access which includes access to Twitter API v2 endpoints only. If you need access to this endpoint, youâ€™ll need to apply for Elevated access via the Developer Portal. You can learn more here: https://developer.twitter.com/en/docs/twitter-api/getting-started/about-twitter-api#v2-access-leve",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mForbidden\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-ec8c35e6d26b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[0mids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mpage\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtweepy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCursor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mapi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_follower_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpages\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m     \u001b[0mids\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tweepy\\cursor.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 86\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tweepy\\cursor.py\u001b[0m in \u001b[0;36mnext\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    108\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext_cursor\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_tweets\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlimit\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 110\u001b[1;33m         data, cursors = self.method(cursor=self.next_cursor,\n\u001b[0m\u001b[0;32m    111\u001b[0m                                     \u001b[1;33m*\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m                                     **self.kwargs)\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tweepy\\api.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[1;33m@\u001b[0m\u001b[0mfunctools\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwraps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpagination_mode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tweepy\\api.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     44\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'payload_list'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpayload_list\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'payload_type'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpayload_type\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpayload_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpayload_list\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpayload_type\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpayload_type\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tweepy\\api.py\u001b[0m in \u001b[0;36mget_follower_ids\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m   2112\u001b[0m         \u001b[0mhttps\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m//\u001b[0m\u001b[0mdeveloper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtwitter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcom\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0men\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mdocs\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mtwitter\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mapi\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mv1\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0maccounts\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;32mand\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0musers\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mfollow\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0msearch\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0musers\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mapi\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mreference\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mfollowers\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mids\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2113\u001b[0m         \"\"\"\n\u001b[1;32m-> 2114\u001b[1;33m         return self.request(\n\u001b[0m\u001b[0;32m   2115\u001b[0m             'GET', 'followers/ids', endpoint_parameters=(\n\u001b[0;32m   2116\u001b[0m                 \u001b[1;34m'user_id'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'screen_name'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'cursor'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'stringify_ids'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'count'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tweepy\\api.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, endpoint, endpoint_parameters, params, headers, json_payload, parser, payload_list, payload_type, post_data, files, require_auth, return_cursors, upload_api, use_cache, **kwargs)\u001b[0m\n\u001b[0;32m    257\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mUnauthorized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m403\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 259\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mForbidden\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    260\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m404\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mNotFound\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mForbidden\u001b[0m: 403 Forbidden\n453 - You currently have Essential access which includes access to Twitter API v2 endpoints only. If you need access to this endpoint, youâ€™ll need to apply for Elevated access via the Developer Portal. You can learn more here: https://developer.twitter.com/en/docs/twitter-api/getting-started/about-twitter-api#v2-access-leve"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print ('API Host', api.host)\n",
    "#print ('API Version', api.api_root)\n",
    "\n",
    "# authenticate our app and make sure it waits when a rate limit gets hit.\n",
    "\n",
    "auth = tweepy.OAuthHandler(api_key,api_key_secret)\n",
    "auth.set_access_token(access_token,access_token_secret)\n",
    "\n",
    "api = tweepy.API(\n",
    "    auth,\n",
    "    wait_on_rate_limit=True\n",
    ")\n",
    "\n",
    "# get a list of followers for professor Chandler.\n",
    "handle = \"37chandler\"\n",
    "ids = []\n",
    "\n",
    "for page in tweepy.Cursor(api.get_follower_ids, screen_name=handle).pages():\n",
    "    ids.extend(page)\n",
    "    time.sleep(30)\n",
    "\n",
    "print(len(ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa67032",
   "metadata": {},
   "source": [
    "## Testing the API\n",
    "\n",
    "The Twitter APIs are quite rich. Let's play around with some of the features before we dive into this section of the assignment. For our testing, it's convenient to have a small data set to play with. We will seed the code with the handle of John Chandler, one of the instructors in this course. His handle is `@37chandler`. Feel free to use a different handle if you would like to look at someone else's data. \n",
    "\n",
    "We will write code to explore a few aspects of the API: \n",
    "\n",
    "1. Pull all the follower IDs for @katymck.\n",
    "1. Explore the user object, which gives us information about Twitter users. \n",
    "1. Pull some user objects for the followers. \n",
    "1. Pull the last few tweets by @katymck.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56fb2673",
   "metadata": {},
   "outputs": [],
   "source": [
    "handle = \"37chandler\"\n",
    "\n",
    "followers = []\n",
    "\n",
    "for page in tweepy.Cursor(api.followers_ids,\n",
    "                          # This is how we will get around the issue of not being able to grab all ids at once\n",
    "                          # Once the rate limit is hit, we will be  that we must wait 15 mins (900 secs)\n",
    "                          wait_on_rate_limit=True, \n",
    "                          wait_on_rate_limit_notify=True, \n",
    "                          compression=True,\n",
    "                          screen_name=handle).pages():\n",
    "\n",
    "    # The page variable comes back as a list, so we have to use .extend rather than .append\n",
    "    followers.extend(page)\n",
    "        \n",
    "        \n",
    "print(f\"Here are the first five follower ids for {handle} out of the {len(followers)} total.\")\n",
    "followers[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dad0a3f",
   "metadata": {},
   "source": [
    "We have the follower IDs, which are unique numbers identifying the user, but we'd like to get some more information on these users. Twitter allows us to pull \"fully hydrated user objects\", which is a fancy way of saying \"all the information about the user\". Let's look at user object for our starting handle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ae5e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "user = api.get_user(handle) \n",
    "pprint(user._json)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6abc5dc6",
   "metadata": {},
   "source": [
    "Now a few questions for you about the user object.\n",
    "\n",
    "Q: How many fields are being returned in the \\_json portion of the user object? \n",
    "\n",
    "A: <!-- Put your answer here --> \n",
    "\n",
    "---\n",
    "\n",
    "Q: Are any of the fields within the user object non-scaler? TK correct term\n",
    "\n",
    "A: <!-- Put your answer here --> \n",
    "\n",
    "---\n",
    "\n",
    "Q: How many friends, followers, favorites, and statuses does this user have? \n",
    "\n",
    "A: <!-- Put your answer here --> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10fbadc0",
   "metadata": {},
   "source": [
    "We can map the follower IDs onto screen names by accessing the screen_name key within the user object. Modify the code below to also print out how many people the follower is following and how many followers they have. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6447c3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_to_lookup = followers[:10]\n",
    "\n",
    "for user_obj in api.lookup_users(ids_to_lookup) :\n",
    "    print(f\"{handle} is followed by {user_obj.screen_name}\")\n",
    "    \n",
    "    # Add code here to print out friends and followers of `handle`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8564d2c",
   "metadata": {},
   "source": [
    "Although you won't need it for this assignment, individual tweets (called \"statuses\" in the API) can be a rich source of text-based data. To illustrate the concepts, let's look at the last few tweets for this user. You are encouraged to explore the `status` object and marvel in the richness of the data that is available. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9fb5c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_count = 0\n",
    "\n",
    "for status in tweepy.Cursor(api.user_timeline, id=handle).items():\n",
    "    tweet_count += 1\n",
    "    \n",
    "    print(f\"The tweet was tweeted at {status.created_at}.\")\n",
    "    print(f\"The original tweet has been retweeted {status.retweet_count} times.\")\n",
    "    \n",
    "    clean_status = status.text\n",
    "    clean_status = clean_status.replace(\"\\n\",\" \")\n",
    "    \n",
    "    print(f\"{clean_status}\")\n",
    "    print(\"\\n\"*2)\n",
    "        \n",
    "    if tweet_count > 10 :\n",
    "        break\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d50726",
   "metadata": {},
   "source": [
    "## Pulling Follower Information\n",
    "\n",
    "In this next section of the assignment, we will pull information about the followers of your two artists. We must first get the follower IDs, then we will be able to \"hydrate\" the IDs, pulling the user objects for them. Once we have those user objects we will extract some fields that we can use in future analyses. \n",
    "\n",
    "\n",
    "The Twitter API only allows users to make 15 requests per 15 minutes when pulling followers. Each request allows you to gather 5000 follower ids. Tweepy will grab the 15 requests quickly then wait 15 minutes, rather than slowly pull the requests over the time period. Before we start grabbing follower IDs, let's first just check how long it would take to pull all of the followers. To do this we use the `followers_count` item from the user object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfdc55ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I'm putting the handles in a list to iterate through below\n",
    "handles = ['robynkonichiwa','cher']\n",
    "\n",
    "# This will iterate through each Twitter handle that we're collecting from\n",
    "for screen_name in handles:\n",
    "    \n",
    "    # Tells Tweepy we want information on the handle we're collecting from\n",
    "    # The next line specifies which information we want, which in this case is the number of followers \n",
    "    user = api.get_user(screen_name) \n",
    "    followers_count = user.followers_count\n",
    "\n",
    "    # Let's see roughly how long it will take to grab all the follower IDs. \n",
    "    print(f'''\n",
    "    @{screen_name} has {followers_count} followers. \n",
    "    That will take roughly {followers_count/(5000*15*4):.2f} hours to pull the followers.\n",
    "    ''')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5f3299",
   "metadata": {},
   "source": [
    "As we pull data for each artist we will write their data to a folder called \"twitter\", so we will make that folder if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a32641",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the \"twitter\" folder here. If you'd like to practice your programming, add functionality \n",
    "# that checks to see if the folder exists. If it does, then \"unlink\" it. Then create a new one.\n",
    "\n",
    "if not os.path.isdir(\"twitter\") : \n",
    "    #shutil.rmtree(\"twitter/\")\n",
    "    os.mkdir(\"twitter\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd58dd90",
   "metadata": {},
   "source": [
    "In this following cells, use the `api.followers_ids` (and the `tweepy.Cursor` functionality) to pull some of the followers for your two artists. As you pull the data, write the follower ids to a file called `[artist name]_followers.txt` in the \"twitter\" folder. For instance, for Cher I would create a file named `cher_followers.txt`. As you pull the data, also store it in an object like a list or a data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5d24ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_followers_to_pull = 60*1000 # feel free to use this to limit the number of followers you pull."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac06010",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify the below code stub to pull the follower IDs and write them to a file. \n",
    "\n",
    "# Grabs the time when we start making requests to the API\n",
    "start_time = datetime.datetime.now()\n",
    "\n",
    "for handle in handles :\n",
    "    \n",
    "    output_file = handle + \"_followers.txt\"\n",
    "    \n",
    "    \n",
    "    # Pull and store the follower IDs\n",
    "    \n",
    "    \n",
    "    # Write the IDs to the output file in the `twitter` folder.\n",
    "        \n",
    "        \n",
    "    # If you've pulled num_followers_to_pull, feel free to break out paged twitter API response\n",
    "            \n",
    "        \n",
    "        \n",
    "# Let's see how long it took to grab all follower IDs\n",
    "end_time = datetime.datetime.now()\n",
    "print(end_time - start_time)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b98e1d",
   "metadata": {},
   "source": [
    "Now that you have your follower ids, gather some information that we can use in future assignments on them. Using the `lookup_users` function, pull the user objects for your followers. These requests are limited to 900 per 15 minutes, but you can request 100 users at a time. At 90,000 users per 15 minutes, the rate limiter on pulls might be bandwidth rather than API limits. \n",
    "\n",
    "Extract the following fields from the user object: \n",
    "\n",
    "* screen_name\t\n",
    "* name\t\n",
    "* id\t\n",
    "* location\t\n",
    "* followers_count\t\n",
    "* friends_count\t\n",
    "* description\n",
    "\n",
    "These can all be accessed via these names in the object. Store the fields with one user per row in a tab-delimited text file with the name `[artist name]_follower_data.txt`. For instance, for Cher I would create a file named `cher_follower_data.txt`. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6dd1120",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# in this cell, do the following\n",
    "# 1. Set up a data frame or dictionary to hold the user information\n",
    "# 2. Use the `lookup_users` api function to pull sets of 100 users at a time\n",
    "# 3. Store the listed fields in your data frame or dictionary.\n",
    "# 4. Write the user information in tab-delimited form to the follower data text file. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18309057",
   "metadata": {},
   "source": [
    "One note: the user's description can have tabs or returns in it, so make sure to clean those out of the description before writing them to the file. Here's an example of how you might do this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2311694f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tricky_description = \"\"\"\n",
    "    Home by Warsan Shire\n",
    "    \n",
    "    no one leaves home unless\n",
    "    home is the mouth of a shark.\n",
    "    you only run for the border\n",
    "    when you see the whole city\n",
    "    running as well.\n",
    "\n",
    "\"\"\"\n",
    "# This won't work in a tab-delimited text file.\n",
    "\n",
    "clean_description = re.sub(r\"\\s+\",\" \",tricky_description)\n",
    "clean_description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c13af3",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Lyrics Scrape\n",
    "\n",
    "This section asks you to pull data from the Twitter API and scrape www.AZLyrics.com. In the notebooks where you do that work you are asked to store the data in specific ways. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "5bd7df77",
   "metadata": {},
   "outputs": [],
   "source": [
    "artists = {'glassanimals':\"https://www.azlyrics.com/g/glassanimals.html\",\n",
    "           'joyner':\"https://www.azlyrics.com/j/joynerlucas.html\"} \n",
    "#'lipa':\"https://www.azlyrics.com/d/dualipa.html\",\n",
    "# we'll use this dictionary to hold both the artist name and the link on AZlyrics\n",
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c236c99b",
   "metadata": {},
   "source": [
    "## A Note on Rate Limiting\n",
    "\n",
    "The lyrics site, www.azlyrics.com, does not have an explicit maximum on number of requests in any one time, but in our testing it appears that too many requests in too short a time will cause the site to stop returning lyrics pages. (Entertainingly, the page that gets returned seems to only have the song title to [a Tom Jones song](https://www.azlyrics.com/lyrics/tomjones/itsnotunusual.html).) \n",
    "\n",
    "Whenever you call `requests.get` to retrieve a page, put a `time.sleep(5 + 10*random.random())` on the next line. This will help you not to get blocked. If you _do_ get blocked, which you can identify if the returned pages are not correct, just request a lyrics page through your browser. You'll be asked to perform a CAPTCHA and then your requests should start working again. \n",
    "\n",
    "## Part 1: Finding Links to Songs Lyrics\n",
    "\n",
    "That general artist page has a list of all songs for that artist with links to the individual song pages. \n",
    "\n",
    "Q: Take a look at the `robots.txt` page on www.azlyrics.com. (You can read more about these pages [here](https://developers.google.com/search/docs/advanced/robots/intro).) Is the scraping we are about to do allowed or disallowed by this page? How do you know? \n",
    "\n",
    "A: <!-- Delete this comment and put your answer here. --> \n",
    "The scrapping we are about to do is not allowed since the robots page disallows pulling lyrics by disallowing \"lyricsdb\".\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "ac9d31ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<a href=\"/lyrics/glassanimals/goldenantlers.html\" target=\"_blank\">Golden Antlers</a>\n",
      "<a href=\"/lyrics/glassanimals/cocoahooves.html\" target=\"_blank\">Cocoa Hooves</a>\n",
      "<a href=\"/lyrics/glassanimals/dustinyourpocket.html\" target=\"_blank\">Dust In Your Pocket</a>\n",
      "<a href=\"/lyrics/glassanimals/cocoahoovesptii.html\" target=\"_blank\">Cocoa Hooves, Pt. II</a>\n",
      "<a href=\"/lyrics/glassanimals/psylla.html\" target=\"_blank\">Psylla</a>\n",
      "<a href=\"/lyrics/glassanimals/blackmambo.html\" target=\"_blank\">Black Mambo</a>\n",
      "<a href=\"/lyrics/glassanimals/exxus.html\" target=\"_blank\">Exxus</a>\n",
      "<a href=\"/lyrics/glassanimals/woozy.html\" target=\"_blank\">Woozy</a>\n",
      "<a href=\"/lyrics/glassanimals/flip.html\" target=\"_blank\">Flip</a>\n",
      "<a href=\"/lyrics/glassanimals/blackmambo.html\" target=\"_blank\">Black Mambo</a>\n",
      "<a href=\"/lyrics/glassanimals/pools.html\" target=\"_blank\">Pools</a>\n",
      "<a href=\"/lyrics/glassanimals/gooey.html\" target=\"_blank\">Gooey</a>\n",
      "<a href=\"/lyrics/glassanimals/wallawalla.html\" target=\"_blank\">Walla Walla</a>\n",
      "None\n",
      "<a href=\"/lyrics/glassanimals/hazey.html\" target=\"_blank\">Hazey</a>\n",
      "<a href=\"/lyrics/glassanimals/toes.html\" target=\"_blank\">Toes</a>\n",
      "<a href=\"/lyrics/glassanimals/wyrd.html\" target=\"_blank\">Wyrd</a>\n",
      "<a href=\"/lyrics/glassanimals/cocoahooves.html\" target=\"_blank\">Cocoa Hooves</a>\n",
      "<a href=\"/lyrics/glassanimals/jdnt.html\" target=\"_blank\">JDNT</a>\n",
      "<a href=\"/lyrics/glassanimals/lifeitself.html\" target=\"_blank\">Life Itself</a>\n",
      "<a href=\"/lyrics/glassanimals/youth.html\" target=\"_blank\">Youth</a>\n",
      "<a href=\"/lyrics/glassanimals/season2episode3.html\" target=\"_blank\">Season 2 Episode 3</a>\n",
      "<a href=\"/lyrics/glassanimals/porksoda.html\" target=\"_blank\">Pork Soda</a>\n",
      "<a href=\"/lyrics/glassanimals/mamasgun.html\" target=\"_blank\">Mama's Gun</a>\n",
      "<a href=\"/lyrics/glassanimals/caneshuga.html\" target=\"_blank\">Cane Shuga</a>\n",
      "<a href=\"/lyrics/glassanimals/premadesandwiches.html\" target=\"_blank\">[Premade Sandwiches]</a>\n",
      "<a href=\"/lyrics/glassanimals/theothersideofparadise.html\" target=\"_blank\">The Other Side Of Paradise</a>\n",
      "<a href=\"/lyrics/glassanimals/takeaslice.html\" target=\"_blank\">Take A Slice</a>\n",
      "<a href=\"/lyrics/glassanimals/poplarst.html\" target=\"_blank\">Poplar St.</a>\n",
      "<a href=\"/lyrics/glassanimals/agnes.html\" target=\"_blank\">Agnes</a>\n",
      "<a href=\"/lyrics/glassanimals/heartshapedbox.html\" target=\"_blank\">Heart-Shaped Box</a>\n",
      "<a href=\"/lyrics/glassanimals/youngandbeautiful.html\" target=\"_blank\">Young And Beautiful</a>\n",
      "<a href=\"/lyrics/glassanimals/dreamland.html\" target=\"_blank\">Dreamland</a>\n",
      "<a href=\"/lyrics/glassanimals/tangerine.html\" target=\"_blank\">Tangerine</a>\n",
      "<a href=\"/lyrics/glassanimals/homemovie1994.html\" target=\"_blank\">((home movie: 1994))</a>\n",
      "<a href=\"/lyrics/glassanimals/hotsugar.html\" target=\"_blank\">Hot Sugar</a>\n",
      "<a href=\"/lyrics/glassanimals/homemoviebtx.html\" target=\"_blank\">((home movie: btx))</a>\n",
      "<a href=\"/lyrics/glassanimals/spaceghostcoasttocoast.html\" target=\"_blank\">Space Ghost Coast To Coast</a>\n",
      "<a href=\"/lyrics/glassanimals/tokyodrifting.html\" target=\"_blank\">Tokyo Drifting</a>\n",
      "<a href=\"/lyrics/glassanimals/melonandthecoconut.html\" target=\"_blank\">Melon And The Coconut</a>\n",
      "<a href=\"/lyrics/glassanimals/yourlovedejavu.html\" target=\"_blank\">Your Love (DÃƒÂ©jÃƒÂ  Vu)</a>\n",
      "<a href=\"/lyrics/glassanimals/waterfallscomingoutyourmouth.html\" target=\"_blank\">Waterfalls Coming Out Your Mouth</a>\n",
      "<a href=\"/lyrics/glassanimals/itsallsoincrediblyloud.html\" target=\"_blank\">It's All So Incredibly Loud</a>\n",
      "<a href=\"/lyrics/glassanimals/homemovierockets.html\" target=\"_blank\">((home movie: rockets))</a>\n",
      "<a href=\"/lyrics/glassanimals/domesticbliss.html\" target=\"_blank\">Domestic Bliss</a>\n",
      "<a href=\"/lyrics/glassanimals/heatwaves.html\" target=\"_blank\">Heat Waves</a>\n",
      "<a href=\"/lyrics/glassanimals/homemovieshoeson.html\" target=\"_blank\">((home movie: shoes on))</a>\n",
      "<a href=\"/lyrics/glassanimals/helium.html\" target=\"_blank\">Helium</a>\n",
      "<a href=\"/lyrics/glassanimals/heatwavesdiploremix.html\" target=\"_blank\">Heat Waves (Diplo Remix)</a>\n",
      "<a href=\"/lyrics/glassanimals/heatwavesshakurremix.html\" target=\"_blank\">Heat Waves (Shakur Remix)</a>\n",
      "<a href=\"/lyrics/glassanimals/idontwannatalkijustwannadance.html\" target=\"_blank\">I Don't Wanna Talk (I Just Wanna Dance)</a>\n",
      "<a href=\"/lyrics/glassanimals/goldlime.html\" target=\"_blank\">Gold Lime</a>\n",
      "<a href=\"/lyrics/glassanimals/heatwavesianndiorremix.html\" target=\"_blank\">Heat Waves (iann dior Remix)</a>\n",
      "<a href=\"/lyrics/glassanimals/holiest.html\" target=\"_blank\">Holiest</a>\n",
      "<a href=\"/lyrics/glassanimals/losecontrol.html\" target=\"_blank\">Lose Control</a>\n",
      "<a href=\"/lyrics/glassanimals/solarpower.html\" target=\"_blank\">Solar Power</a>\n",
      "<a href=\"/lyrics/glassanimals/spaceghostcoasttocoastremix.html\" target=\"_blank\">Space Ghost Coast To Coast (Remix)</a>\n",
      "<a href=\"/lyrics/glassanimals/tangerineremix.html\" target=\"_blank\">Tangerine (Remix)</a>\n",
      "<a href=\"/lyrics/joynerlucas/introskit.html\" target=\"_blank\">Intro (Skit)</a>\n",
      "<a href=\"/lyrics/joynerlucas/mansion.html\" target=\"_blank\">Mansion</a>\n",
      "<a href=\"/lyrics/joynerlucas/thatsok.html\" target=\"_blank\">That's OK</a>\n",
      "<a href=\"/lyrics/joynerlucas/longway.html\" target=\"_blank\">Long Way</a>\n",
      "<a href=\"/lyrics/joynerlucas/getinskit.html\" target=\"_blank\">Get In (Skit)</a>\n",
      "<a href=\"/lyrics/joynerlucas/ridingsolo.html\" target=\"_blank\">Riding Solo</a>\n",
      "<a href=\"/lyrics/joynerlucas/oppositesattract.html\" target=\"_blank\">Opposites Attract</a>\n",
      "<a href=\"/lyrics/joynerlucas/wwjdskit.html\" target=\"_blank\">WWJD (Skit)</a>\n",
      "<a href=\"/lyrics/joynerlucas/wwjd.html\" target=\"_blank\">WWJD</a>\n",
      "<a href=\"/lyrics/joynerlucas/halfnigger.html\" target=\"_blank\">Half Nigga</a>\n",
      "<a href=\"/lyrics/joynerlucas/sheknows.html\" target=\"_blank\">She Know's</a>\n",
      "<a href=\"/lyrics/joynerlucas/shootingstar.html\" target=\"_blank\">Shooting Star</a>\n",
      "<a href=\"/lyrics/joynerlucas/lookaroundme.html\" target=\"_blank\">Look Around Me</a>\n",
      "<a href=\"/lyrics/joynerlucas/beluxiaskit.html\" target=\"_blank\">Beluxia (Skit)</a>\n",
      "<a href=\"/lyrics/joynerlucas/shedontneedme.html\" target=\"_blank\">She Don't Need Me</a>\n",
      "<a href=\"/lyrics/joynerlucas/bonfireskit.html\" target=\"_blank\">Bonfire (Skit)</a>\n",
      "<a href=\"/lyrics/joynerlucas/rosscapachioni.html\" target=\"_blank\">Ross Capicchioni</a>\n",
      "<a href=\"/lyrics/joynerlucas/rockbottom.html\" target=\"_blank\">Rock Bottom</a>\n",
      "<a href=\"/lyrics/joynerlucas/dontshoot.html\" target=\"_blank\">Don't Shoot</a>\n",
      "<a href=\"/lyrics/joynerlucas/thefeelinginterlude.html\" target=\"_blank\">The Feeling (Interlude)</a>\n",
      "<a href=\"/lyrics/joynerlucas/allover.html\" target=\"_blank\">All Over</a>\n",
      "<a href=\"/lyrics/joynerlucas/ultrasound.html\" target=\"_blank\">Ultrasound</a>\n",
      "<a href=\"/lyrics/joynerlucas/lovely.html\" target=\"_blank\">Lovely</a>\n",
      "<a href=\"/lyrics/joynerlucas/fym.html\" target=\"_blank\">FYM</a>\n",
      "<a href=\"/lyrics/joynerlucas/keepit100.html\" target=\"_blank\">Keep It 100</a>\n",
      "<a href=\"/lyrics/joynerlucas/winterblues.html\" target=\"_blank\">Winter Blues</a>\n",
      "<a href=\"/lyrics/joynerlucas/justlikeyou.html\" target=\"_blank\">Just Like You</a>\n",
      "<a href=\"/lyrics/joynerlucas/justbecause.html\" target=\"_blank\">Just Because</a>\n",
      "<a href=\"/lyrics/joynerlucas/lullaby.html\" target=\"_blank\">Lullaby</a>\n",
      "<a href=\"/lyrics/joynerlucas/waytogo.html\" target=\"_blank\">Way To Go</a>\n",
      "<a href=\"/lyrics/joynerlucas/lookwhatyoumademedo.html\" target=\"_blank\">Look What You Made Me Do</a>\n",
      "<a href=\"/lyrics/joynerlucas/wegonbealright.html\" target=\"_blank\">We Gon Be Alright</a>\n",
      "<a href=\"/lyrics/joynerlucas/forever.html\" target=\"_blank\">Forever</a>\n",
      "<a href=\"/lyrics/joynerlucas/ineedmore.html\" target=\"_blank\">I Need More</a>\n",
      "<a href=\"/lyrics/joynerlucas/literally.html\" target=\"_blank\">Literally</a>\n",
      "<a href=\"/lyrics/joynerlucas/imsorry.html\" target=\"_blank\">Sorry</a>\n",
      "<a href=\"/lyrics/joynerlucas/onelonelynight.html\" target=\"_blank\">One Lonely Night</a>\n",
      "<a href=\"/lyrics/joynerlucas/screeningevaluationskit.html\" target=\"_blank\">Screening Evaluation (Skit)</a>\n",
      "<a href=\"/lyrics/joynerlucas/iliedintro.html\" target=\"_blank\">I Lied (Intro)</a>\n",
      "<a href=\"/lyrics/joynerlucas/isis.html\" target=\"_blank\">ISIS</a>\n",
      "<a href=\"/lyrics/joynerlucas/thewar.html\" target=\"_blank\">The War</a>\n",
      "<a href=\"/lyrics/joynerlucas/chrisskit.html\" target=\"_blank\">Chris (Skit)</a>\n",
      "<a href=\"/lyrics/joynerlucas/ilove.html\" target=\"_blank\">I Love</a>\n",
      "<a href=\"/lyrics/joynerlucas/devilswork.html\" target=\"_blank\">Devil's Work</a>\n",
      "<a href=\"/lyrics/joynerlucas/lotto.html\" target=\"_blank\">Lotto</a>\n",
      "<a href=\"/lyrics/joynerlucas/kevinskit.html\" target=\"_blank\">Kevin (Skit)</a>\n",
      "<a href=\"/lyrics/joynerlucas/goldmine.html\" target=\"_blank\">Gold Mine</a>\n",
      "<a href=\"/lyrics/joynerlucas/finally.html\" target=\"_blank\">Finally</a>\n",
      "<a href=\"/lyrics/joynerlucas/10bands.html\" target=\"_blank\">10 Bands</a>\n",
      "<a href=\"/lyrics/joynerlucas/revengeintro.html\" target=\"_blank\">Revenge</a>\n",
      "<a href=\"/lyrics/joynerlucas/comprehensiveevaluationskit.html\" target=\"_blank\">Comprehensive Evaluation (Skit)</a>\n",
      "<a href=\"/lyrics/joynerlucas/adhd.html\" target=\"_blank\">ADHD</a>\n",
      "<a href=\"/lyrics/joynerlucas/stillcantlove.html\" target=\"_blank\">Still Can't Love</a>\n",
      "<a href=\"/lyrics/joynerlucas/will.html\" target=\"_blank\">Will</a>\n",
      "<a href=\"/lyrics/joynerlucas/brokeandstupid.html\" target=\"_blank\">Broke And Stupid</a>\n",
      "<a href=\"/lyrics/joynerlucas/whenigrowupintro.html\" target=\"_blank\">When I Grow Up (Intro)</a>\n",
      "<a href=\"/lyrics/joynerlucas/evolution.html\" target=\"_blank\">Evolution</a>\n",
      "<a href=\"/lyrics/joynerlucas/onthisway.html\" target=\"_blank\">On This Way</a>\n",
      "<a href=\"/lyrics/joynerlucas/thingsiveseen.html\" target=\"_blank\">Things I've Seen</a>\n",
      "<a href=\"/lyrics/joynerlucas/zimzimma.html\" target=\"_blank\">Zim Zimma</a>\n",
      "<a href=\"/lyrics/joynerlucas/tattletalesskit.html\" target=\"_blank\">Tattle Tales (Skit)</a>\n",
      "<a href=\"/lyrics/joynerlucas/snitch.html\" target=\"_blank\">Snitch</a>\n",
      "<a href=\"/lyrics/joynerlucas/str8likedat.html\" target=\"_blank\">Str8 Like Dat</a>\n",
      "<a href=\"/lyrics/joynerlucas/fallslowly.html\" target=\"_blank\">Fall Slowly</a>\n",
      "<a href=\"/lyrics/joynerlucas/theproblem.html\" target=\"_blank\">The Problem</a>\n",
      "<a href=\"/lyrics/joynerlucas/legend.html\" target=\"_blank\">Legend</a>\n",
      "<a href=\"/lyrics/joynerlucas/fathersdayskit.html\" target=\"_blank\">Father's Day (Skit)</a>\n",
      "<a href=\"/lyrics/joynerlucas/likeariver.html\" target=\"_blank\">Like A River</a>\n",
      "<a href=\"/lyrics/joynerlucas/backinbloodremix.html\" target=\"_blank\">Back In Blood (Remix)</a>\n",
      "<a href=\"/lyrics/joynerlucas/backwords.html\" target=\"_blank\">Back Words</a>\n",
      "<a href=\"/lyrics/joynerlucas/bankaccountremix.html\" target=\"_blank\">Bank Account (Remix)</a>\n",
      "<a href=\"/lyrics/joynerlucas/dnaremix.html\" target=\"_blank\">DNA. (Remix)</a>\n",
      "<a href=\"/lyrics/joynerlucas/dreamsunfold.html\" target=\"_blank\">Dreams Unfold</a>\n",
      "<a href=\"/lyrics/joynerlucas/duckduckgoose.html\" target=\"_blank\">Duck Duck Goose</a>\n",
      "<a href=\"/lyrics/joynerlucas/frozen.html\" target=\"_blank\">Frozen</a>\n",
      "<a href=\"/lyrics/joynerlucas/fuckyourfeelings.html\" target=\"_blank\">Fuck Your Feelings</a>\n",
      "<a href=\"/lyrics/joynerlucas/guccigangremix.html\" target=\"_blank\">Gucci Gang (Remix)</a>\n",
      "<a href=\"/lyrics/joynerlucas/happybirthday.html\" target=\"_blank\">Happy Birthday</a>\n",
      "<a href=\"/lyrics/joynerlucas/idontdie.html\" target=\"_blank\">I Don't Die</a>\n",
      "<a href=\"/lyrics/joynerlucas/imnotaracist.html\" target=\"_blank\">I'm Not Racist</a>\n",
      "<a href=\"/lyrics/joynerlucas/jumanji.html\" target=\"_blank\">Jumanji</a>\n",
      "<a href=\"/lyrics/joynerlucas/justletgo.html\" target=\"_blank\">Just Let Go</a>\n",
      "<a href=\"/lyrics/joynerlucas/latetotheparty.html\" target=\"_blank\">Late To The Party</a>\n",
      "<a href=\"/lyrics/joynerlucas/littyfreestyle.html\" target=\"_blank\">Litty Freestyle</a>\n",
      "<a href=\"/lyrics/joynerlucas/lookaliveremix.html\" target=\"_blank\">Look Alive (Remix)</a>\n",
      "<a href=\"/lyrics/joynerlucas/lottoremix.html\" target=\"_blank\">Lotto (Remix)</a>\n",
      "<a href=\"/lyrics/joynerlucas/maskoffremixmaskon.html\" target=\"_blank\">Mask Off Remix (Mask On)</a>\n",
      "<a href=\"/lyrics/joynerlucas/myescape.html\" target=\"_blank\">My Escape</a>\n",
      "<a href=\"/lyrics/joynerlucas/pandaremix.html\" target=\"_blank\">Panda Remix</a>\n",
      "<a href=\"/lyrics/joynerlucas/rambo.html\" target=\"_blank\">Rambo</a>\n",
      "<a href=\"/lyrics/joynerlucas/ramenoj.html\" target=\"_blank\">Ramen &amp; OJ</a>\n",
      "<a href=\"https://www.azlyrics.com/lyrics/meekmill/runit.html\" target=\"_blank\">Run It</a>\n",
      "<a href=\"/lyrics/joynerlucas/sayhellotoadele.html\" target=\"_blank\">Say Hello To Adele</a>\n",
      "<a href=\"/lyrics/joynerlucas/shootmyshot.html\" target=\"_blank\">Shoot My Shot</a>\n",
      "<a href=\"/lyrics/joynerlucas/slowdown.html\" target=\"_blank\">Slow Down</a>\n",
      "<a href=\"/lyrics/joynerlucas/snapple.html\" target=\"_blank\">Snapple</a>\n",
      "<a href=\"/lyrics/joynerlucas/sometimes.html\" target=\"_blank\">Sometimes</a>\n",
      "<a href=\"/lyrics/joynerlucas/strangerthings.html\" target=\"_blank\">Stranger Things</a>\n",
      "<a href=\"/lyrics/joynerlucas/sugeremix.html\" target=\"_blank\">Suge (Remix)</a>\n",
      "<a href=\"/lyrics/joynerlucas/tapdance.html\" target=\"_blank\">Tapdance</a>\n",
      "<a href=\"/lyrics/joynerlucas/whatifiwasgay.html\" target=\"_blank\">What If I Was Gay</a>\n",
      "<a href=\"/lyrics/joynerlucas/whatspoppinremixwhatsgucci.html\" target=\"_blank\">What's Poppin Remix (What's Gucci)</a>\n",
      "<a href=\"/lyrics/joynerlucas/whogottheyayo.html\" target=\"_blank\">Who Got The Yayo?</a>\n",
      "<a href=\"/lyrics/joynerlucas/willremix.html\" target=\"_blank\">Will (Remix)</a>\n",
      "<a href=\"/lyrics/joynerlucas/wordswithfriends.html\" target=\"_blank\">Words With Friends</a>\n",
      "<a href=\"https://www.azlyrics.com/lyrics/royceda59/wrotemywayoutremix.html\" target=\"_blank\">Wrote My Way Out (Remix)</a>\n",
      "<a href=\"/lyrics/joynerlucas/yenotcrazy.html\" target=\"_blank\">Ye Not Crazy</a>\n",
      "<a href=\"/lyrics/joynerlucas/yourheart.html\" target=\"_blank\">Your Heart</a>\n",
      "<a href=\"/lyrics/joynerlucas/zezefreestyle.html\" target=\"_blank\">Zeze Freestyle</a>\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Let's set up a dictionary of lists to hold our links\n",
    "lyrics_pages = defaultdict(list)\n",
    "\n",
    "for artist, artist_page in artists.items() :\n",
    "    # request the page and sleep\n",
    "    r = requests.get(artist_page)\n",
    "    time.sleep(5 + 10*random.random())\n",
    "\n",
    "    # now extract the links to lyrics pages from this page\n",
    "    soup = BeautifulSoup(r.text, 'html.parser')\n",
    "    listalbum = soup.find_all(\"div\", \"listalbum-item\")\n",
    "    \n",
    "    links = []\n",
    "    for link in soup.find_all(\"div\", \"listalbum-item\"):\n",
    "        text = str(link.a)\n",
    "        #print(text)\n",
    "        #converts ...<a href=\"/lyrics/joynerlucas/sugeremix.html\" target=\"_blank\"...\n",
    "        # to /lyrics/joynerlucas/introskit.html\n",
    "        try:\n",
    "             lyricLink = re.search('href=\\\"(.+?)\\\" t', text).group(1)\n",
    "        except AttributeError:\n",
    "            pass\n",
    "       \n",
    "        if (lyricLink[0:4] != \"http\"):\n",
    "            lyricLink = \"https://www.azlyrics.com\" + lyricLink\n",
    "        # store the links `lyrics_pages` where the key is the artist and the\n",
    "        # value is a list of links.\n",
    "        lyrics_pages[artist].append(lyricLink)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "87e47213",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.azlyrics.com/lyrics/glassanimals/goldenantlers.html',\n",
       " 'https://www.azlyrics.com/lyrics/glassanimals/cocoahooves.html',\n",
       " 'https://www.azlyrics.com/lyrics/glassanimals/dustinyourpocket.html',\n",
       " 'https://www.azlyrics.com/lyrics/glassanimals/cocoahoovesptii.html',\n",
       " 'https://www.azlyrics.com/lyrics/glassanimals/psylla.html',\n",
       " 'https://www.azlyrics.com/lyrics/glassanimals/blackmambo.html',\n",
       " 'https://www.azlyrics.com/lyrics/glassanimals/exxus.html',\n",
       " 'https://www.azlyrics.com/lyrics/glassanimals/woozy.html',\n",
       " 'https://www.azlyrics.com/lyrics/glassanimals/flip.html',\n",
       " 'https://www.azlyrics.com/lyrics/glassanimals/blackmambo.html',\n",
       " 'https://www.azlyrics.com/lyrics/glassanimals/pools.html',\n",
       " 'https://www.azlyrics.com/lyrics/glassanimals/gooey.html',\n",
       " 'https://www.azlyrics.com/lyrics/glassanimals/wallawalla.html',\n",
       " 'https://www.azlyrics.com/lyrics/glassanimals/wallawalla.html',\n",
       " 'https://www.azlyrics.com/lyrics/glassanimals/hazey.html',\n",
       " 'https://www.azlyrics.com/lyrics/glassanimals/toes.html',\n",
       " 'https://www.azlyrics.com/lyrics/glassanimals/wyrd.html',\n",
       " 'https://www.azlyrics.com/lyrics/glassanimals/cocoahooves.html',\n",
       " 'https://www.azlyrics.com/lyrics/glassanimals/jdnt.html',\n",
       " 'https://www.azlyrics.com/lyrics/glassanimals/lifeitself.html',\n",
       " 'https://www.azlyrics.com/lyrics/glassanimals/youth.html',\n",
       " 'https://www.azlyrics.com/lyrics/glassanimals/season2episode3.html',\n",
       " 'https://www.azlyrics.com/lyrics/glassanimals/porksoda.html',\n",
       " 'https://www.azlyrics.com/lyrics/glassanimals/mamasgun.html',\n",
       " 'https://www.azlyrics.com/lyrics/glassanimals/caneshuga.html',\n",
       " 'https://www.azlyrics.com/lyrics/glassanimals/premadesandwiches.html',\n",
       " 'https://www.azlyrics.com/lyrics/glassanimals/theothersideofparadise.html',\n",
       " 'https://www.azlyrics.com/lyrics/glassanimals/takeaslice.html',\n",
       " 'https://www.azlyrics.com/lyrics/glassanimals/poplarst.html',\n",
       " 'https://www.azlyrics.com/lyrics/glassanimals/agnes.html',\n",
       " 'https://www.azlyrics.com/lyrics/glassanimals/heartshapedbox.html',\n",
       " 'https://www.azlyrics.com/lyrics/glassanimals/youngandbeautiful.html',\n",
       " 'https://www.azlyrics.com/lyrics/glassanimals/dreamland.html',\n",
       " 'https://www.azlyrics.com/lyrics/glassanimals/tangerine.html',\n",
       " 'https://www.azlyrics.com/lyrics/glassanimals/homemovie1994.html',\n",
       " 'https://www.azlyrics.com/lyrics/glassanimals/hotsugar.html',\n",
       " 'https://www.azlyrics.com/lyrics/glassanimals/homemoviebtx.html',\n",
       " 'https://www.azlyrics.com/lyrics/glassanimals/spaceghostcoasttocoast.html',\n",
       " 'https://www.azlyrics.com/lyrics/glassanimals/tokyodrifting.html',\n",
       " 'https://www.azlyrics.com/lyrics/glassanimals/melonandthecoconut.html',\n",
       " 'https://www.azlyrics.com/lyrics/glassanimals/yourlovedejavu.html',\n",
       " 'https://www.azlyrics.com/lyrics/glassanimals/waterfallscomingoutyourmouth.html',\n",
       " 'https://www.azlyrics.com/lyrics/glassanimals/itsallsoincrediblyloud.html',\n",
       " 'https://www.azlyrics.com/lyrics/glassanimals/homemovierockets.html',\n",
       " 'https://www.azlyrics.com/lyrics/glassanimals/domesticbliss.html',\n",
       " 'https://www.azlyrics.com/lyrics/glassanimals/heatwaves.html',\n",
       " 'https://www.azlyrics.com/lyrics/glassanimals/homemovieshoeson.html',\n",
       " 'https://www.azlyrics.com/lyrics/glassanimals/helium.html',\n",
       " 'https://www.azlyrics.com/lyrics/glassanimals/heatwavesdiploremix.html',\n",
       " 'https://www.azlyrics.com/lyrics/glassanimals/heatwavesshakurremix.html',\n",
       " 'https://www.azlyrics.com/lyrics/glassanimals/idontwannatalkijustwannadance.html',\n",
       " 'https://www.azlyrics.com/lyrics/glassanimals/goldlime.html',\n",
       " 'https://www.azlyrics.com/lyrics/glassanimals/heatwavesianndiorremix.html',\n",
       " 'https://www.azlyrics.com/lyrics/glassanimals/holiest.html',\n",
       " 'https://www.azlyrics.com/lyrics/glassanimals/losecontrol.html',\n",
       " 'https://www.azlyrics.com/lyrics/glassanimals/solarpower.html',\n",
       " 'https://www.azlyrics.com/lyrics/glassanimals/spaceghostcoasttocoastremix.html',\n",
       " 'https://www.azlyrics.com/lyrics/glassanimals/tangerineremix.html']"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(lyrics_pages[\"glassanimals\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c285ec1",
   "metadata": {},
   "source": [
    "Let's make sure we have enough lyrics pages to scrape. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "ae4cda68",
   "metadata": {},
   "outputs": [],
   "source": [
    "for artist, lp in lyrics_pages.items() :\n",
    "    assert(len(set(lp)) > 20) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "edca10d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For glassanimals we have 58.\n",
      "The full pull will take for this artist will take 0.16 hours.\n",
      "For joyner we have 109.\n",
      "The full pull will take for this artist will take 0.3 hours.\n"
     ]
    }
   ],
   "source": [
    "# Let's see how long it's going to take to pull these lyrics \n",
    "# if we're waiting `5 + 10*random.random()` seconds \n",
    "for artist, links in lyrics_pages.items() : \n",
    "    print(f\"For {artist} we have {len(links)}.\")\n",
    "    print(f\"The full pull will take for this artist will take {round(len(links)*10/3600,2)} hours.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011be6c6",
   "metadata": {},
   "source": [
    "## Part 2: Pulling Lyrics\n",
    "\n",
    "Now that we have the links to our lyrics pages, let's go scrape them! Here are the steps for this part. \n",
    "\n",
    "1. Create an empty folder in our repo called \"lyrics\". \n",
    "1. Iterate over the artists in `lyrics_pages`. \n",
    "1. Create a subfolder in lyrics with the artist's name. For instance, if the artist was Cher you'd have `lyrics/cher/` in your repo.\n",
    "1. Iterate over the pages. \n",
    "1. Request the page and extract the lyrics from the returned HTML file using BeautifulSoup.\n",
    "1. Use the function below, `generate_filename_from_url`, to create a filename based on the lyrics page, then write the lyrics to a text file with that name. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "67693711",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_filename_from_link(link) :\n",
    "    \n",
    "    if not link :\n",
    "        return None\n",
    "    \n",
    "    # drop the http or https and the html\n",
    "    name = link.replace(\"https\",\"\").replace(\"http\",\"\")\n",
    "    name = link.replace(\".html\",\"\")\n",
    "\n",
    "    name = name.replace(\"/lyrics/\",\"\")\n",
    "    \n",
    "    # Replace useless chareacters with UNDERSCORE\n",
    "    name = name.replace(\"://\",\"\").replace(\".\",\"_\").replace(\"/\",\"_\")\n",
    "    \n",
    "    # tack on .txt\n",
    "    name = name + \".txt\"\n",
    "    \n",
    "    return(name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "94a78c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the lyrics folder here. If you'd like to practice your programming, add functionality \n",
    "# that checks to see if the folder exists. If it does, then use shutil.rmtree to remove it and create a new one.\n",
    "import shutil\n",
    "if os.path.isdir(\"lyrics\") : \n",
    "    shutil.rmtree(\"lyrics/\")\n",
    "os.mkdir(\"lyrics\")\n",
    "\n",
    "#os.chdir(r\"C:\\Users\\elfek\\datamining\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "8c5cf266",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glassanimals\n",
      "joyner\n"
     ]
    }
   ],
   "source": [
    "for artist in lyrics_pages :\n",
    "    print(artist)\n",
    "    \n",
    "    # Let's see how long it's going to take to pull these lyrics \n",
    "# if we're waiting `5 + 10*random.random()` seconds \n",
    "for artist, links in lyrics_pages.items() : \n",
    "    print(f\"For {artist} we have {len(links)}.\")\n",
    "    print(f\"The full pull will take for this artist will take {round(len(links)*10/3600,2)} hours.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d655b687",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_stub = \"https://www.azlyrics.com\" \n",
    "start = time.time()\n",
    "alltext = \"\"\n",
    "total_pages = 0 \n",
    "\n",
    "for artist in lyrics_pages :\n",
    "\n",
    "    # Use this space to carry out the following steps: \n",
    "    \n",
    "    # 1. Build a subfolder for the artist\n",
    "    if os.path.isdir(\"lyrics/joyner\") : \n",
    "        shutil.rmtree(\"lyrics/joyner/\")\n",
    "    os.mkdir(\"lyrics/joyner\")\n",
    "    \n",
    "    if os.path.isdir(\"lyrics/glassanimals\") : \n",
    "        shutil.rmtree(\"lyrics/glassanimals/\")\n",
    "    os.mkdir(\"lyrics/glassanimals\")\n",
    "    \n",
    "    # 2. Iterate over the lyrics pages\n",
    "    #alltext = []\n",
    "    \n",
    "    for links in lyrics_pages[artist]: \n",
    "    # 3. Request the lyrics page. \n",
    "        # Don't forget to add a line like `time.sleep(5 + 10*random.random())`\n",
    "        # to sleep after making the request\n",
    "        r = requests.get(links)\n",
    "        time.sleep(5 + 10*random.random())\n",
    "        # now extract the links to lyrics pages from this page\n",
    "        # **Already extracted links to lyrics!!**\n",
    "    \n",
    "    # 4. Extract the title and lyrics from the page.\n",
    "        soup = BeautifulSoup(r.text, 'html.parser')\n",
    "        soup.title\n",
    "        last_div_tag = soup.find(\"div\", \"container main-page\")\n",
    "\n",
    "        for string in last_div_tag.stripped_strings:\n",
    "            alltext = alltext + str(string)\n",
    "    # 5. Write out the title, two returns ('\\n'), and the lyrics. Use `generate_filename_from_url`\n",
    "    #    to generate the filename. \n",
    "    \n",
    "    # Remember to pull at least 20 songs per artist. It may be fun to pull all the songs for the artist\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48329b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "        text = str(link.a)\n",
    "        #print(text)\n",
    "        #converts ...<a href=\"/lyrics/joynerlucas/sugeremix.html\" target=\"_blank\"...\n",
    "        # to /lyrics/joynerlucas/introskit.html\n",
    "        try:\n",
    "             lyricLink = re.search('href=\\\"(.+?)\\\" t', text).group(1)\n",
    "        except AttributeError:\n",
    "            pass\n",
    "       \n",
    "        if (lyricLink[0:4] != \"http\"):\n",
    "            lyricLink = \"https://www.azlyrics.com\" + lyricLink\n",
    "        # store the links `lyrics_pages` where the key is the artist and the\n",
    "        # value is a list of links.\n",
    "        lyrics_pages[artist].append(lyricLink)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "7d4daf8f",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NavigableString' object has no attribute 'contents'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-246-78becd8bdfbe>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mhead_tag\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtitle_tag\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msoup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontents\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtitle_tag\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontents\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontents\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\bs4\\element.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, attr)\u001b[0m\n\u001b[0;32m    961\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    962\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 963\u001b[1;33m             raise AttributeError(\n\u001b[0m\u001b[0;32m    964\u001b[0m                 \"'%s' object has no attribute '%s'\" % (\n\u001b[0;32m    965\u001b[0m                     self.__class__.__name__, attr))\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NavigableString' object has no attribute 'contents'"
     ]
    }
   ],
   "source": [
    "head_tag = soup.head\n",
    "title_tag = head_tag.contents[0]\n",
    "\n",
    "head_tag\n",
    "title_tag,soup.contents[0].name\n",
    "text = title_tag.contents[0]\n",
    "text.contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "cbab7dc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<title>Joyner Lucas - Intro (Skit) Lyrics | AZLyrics.com</title>"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#for artist in lyrics_pages :\n",
    "#    print(artist)\n",
    "#    for links in lyrics_pages[artist]: \n",
    "#        print(links)\n",
    "\n",
    "r = requests.get(lyrics_pages[\"joyner\"][0])\n",
    "soup = BeautifulSoup(r.text, 'html.parser')\n",
    "soup.title\n",
    "listalbum = soup.find_all(\"i\")\n",
    "listalbum = soup.find_all(\"b\",\"Intro (Skit)\")\n",
    "listalbum = soup.find_all(\"div\", \"div-share noprint\")\n",
    "\n",
    "last_div_tag = soup.find(\"div\", \"container main-page\")\n",
    "\n",
    "for string in last_div_tag.stripped_strings:\n",
    "    print(repr(string))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "a1a58a8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Joyner Lucas - Intro (Skit) Lyrics | AZLyrics.com'\n",
      "'A'\n",
      "'B'\n",
      "'C'\n",
      "'D'\n",
      "'E'\n",
      "'F'\n",
      "'G'\n",
      "'H'\n",
      "'I'\n",
      "'J'\n",
      "'K'\n",
      "'L'\n",
      "'M'\n",
      "'N'\n",
      "'O'\n",
      "'P'\n",
      "'Q'\n",
      "'R'\n",
      "'S'\n",
      "'T'\n",
      "'U'\n",
      "'V'\n",
      "'W'\n",
      "'X'\n",
      "'Y'\n",
      "'Z'\n",
      "'#'\n",
      "'Search'\n",
      "'\"Intro (Skit)\" lyrics'\n",
      "'Joyner Lucas Lyrics'\n",
      "'\"Intro (Skit)\"'\n",
      "'[*Nightmare*]'\n",
      "'[Homie X:]'\n",
      "\"Damn bro, sounds like you were having a bad dream huh? sounded like somebody was raping you in your sleep ha, that's what it sounded like.\"\n",
      "'[Joyner:]'\n",
      "'Shut the fuck up man.'\n",
      "'[Homie X:]'\n",
      "'You good?'\n",
      "'[Joyner:]'\n",
      "\"Yea am good man, we just need to get the fuck off this planet man, I'm tired of this shit already.\"\n",
      "'[Homie X:]'\n",
      "'And go where?'\n",
      "'[Joyner:]'\n",
      "\"I don't know, something's just telling me to go man, I think you should come wit me.\"\n",
      "'[Homie X:]'\n",
      "'Know what, that really sounds like a bad idea, fuck that.'\n",
      "'[Joyner:]'\n",
      "'What bro?'\n",
      "'[Homie X:]'\n",
      "\"Last time you had a bright idea we went to the sun, you almost got us killed. Remember that? My skin ain't been the same since nigga fuck you. Nope, the answer is no, ask me five minutes later from now the answer is no.\"\n",
      "'[Joyner:]'\n",
      "\"Nigga you always told me that you would never succeed unless you'd die, I'd never forget that shit.\"\n",
      "'[Homie X:]'\n",
      "\"Dumbass, I... It's unless you try, and I ain't tryin' to die tonight. Cancel me out your plans for this one I'm good. Stayin my ass right the fuck here nigga.\"\n",
      "'[Joyner:]'\n",
      "\"You know, sorry you feel that way my man, I got this brochure right here and ahhÃ¢\\x80Â¦ I see planet Earth got some of the badest bitches we've ever seen in our life.\"\n",
      "'[Homie X:]'\n",
      "'Man give me that. Let me see that shit.'\n",
      "'[Joyner:]'\n",
      "\"But I guess you don't wanna go so don't worry bout it.\"\n",
      "'[Homie X:]'\n",
      "'What?!'\n",
      "'[Joyner:]'\n",
      "\"Ahh don't worry bout it.\"\n",
      "'[Homie X:]'\n",
      "\"Nigga what you mean?? Ay I go put fuel in this shit right now, better get your ass up let's go. Shoulda said this shit from the first place nigga, sh I woulda been said yes let's go man.\"\n",
      "'[Joyner:]'\n",
      "\"Hehehe ahh I'd figure you'd say that, well pack your shit, let's take off.\"\n",
      "'Submit Corrections'\n",
      "'AZLyrics'\n",
      "'J'\n",
      "'Joyner Lucas Lyrics'\n",
      "'mixtape:'\n",
      "'\"Along Came Joyner\"'\n",
      "'(2015)'\n",
      "'Intro (Skit)'\n",
      "'Mansion'\n",
      "\"That's OK\"\n",
      "'Long Way'\n",
      "'Get In (Skit)'\n",
      "'Riding Solo'\n",
      "'Opposites Attract'\n",
      "'WWJD (Skit)'\n",
      "'WWJD'\n",
      "'Half Nigga'\n",
      "\"She Know's\"\n",
      "'Shooting Star'\n",
      "'Look Around Me'\n",
      "'Beluxia (Skit)'\n",
      "\"She Don't Need Me\"\n",
      "'Bonfire (Skit)'\n",
      "'Ross Capicchioni'\n",
      "'Rock Bottom'\n",
      "\"Don't Shoot\"\n",
      "'The Feeling (Interlude)'\n",
      "'All Over'\n",
      "'You May Also Like'\n",
      "'Logic - \"Nikki\"'\n",
      "\"I can feel you in my lungs, feel you in my veins\\nBloodstream only way to make it to my brain\\nI tried some others but man they just not as good as you\\nGoing crazy 'cause I only feel this good with...\"\n",
      "'Big Sean - \"Bounce Back\"'\n",
      "\"Hitmaka\\nIf Young Metro don't trust you, I'm gon' shoot you Last night took a L, but tonight I bounce back\\nWake up every morning, by the night, I count stacks\\nKnew that ass was real when I hit, it...\"\n",
      "'ScHoolboy Q - \"Overtime\"'\n",
      "\"Righteous, righteous\\nWoo!\\nGoddamn Baby let me know itÃ¢\\x80\\x99s mine\\nAnd I might put in overtime\\nUnderstanding overnight\\nYou know tonight ain't a sober night I wanna fuck right now\\nI wanna fuck right now\\nI...\"\n",
      "'Vic Mensa - \"New Bae\"'\n",
      "\"Let me pick my face up off the floor I'm off the D'USSÃƒ\\x89\\nI've been going so hard this week and shit it's only Tuesday\\nI left my bitch at home, I think I need a new bae\\nI left my bitch at home, I...\"\n",
      "'2 Chainz - \"PROUD\"'\n",
      "\"Yeah, do it for the hood, nigga, rep\\nYeah, Soufside with an F 'cause I'm fresh\\nDo it for the hood, nigga, rep\\nSoufside with an F 'cause I'm fresh\\nTryna make my momma proud, uh\\nI ain't tryna let my...\"\n",
      "'Search'\n",
      "'Submit Lyrics'\n",
      "'Soundtracks'\n",
      "'Facebook'\n",
      "'Contact Us'\n",
      "'Advertise Here'\n",
      "'Privacy Policy'\n",
      "'Cookie Policy'\n",
      "'DMCA Policy'\n",
      "'Lyrics licensed by'\n"
     ]
    }
   ],
   "source": [
    "for string in soup.stripped_strings:\n",
    "    print(repr(string))\n",
    "    \n",
    "allText = ''\n",
    "try:\n",
    "     songTitle = re.search(\"\\'Search\\'\"(.+?)\\\" t', allText).group(1)\n",
    "except AttributeError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e903c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get(lyrics_pages[\"glassanimals\"][0])\n",
    "soup = BeautifulSoup(r.text, 'html.parser')\n",
    "print(soup.title)\n",
    "\n",
    "listalbum = soup.find_all(\"div\", \"div-share noprint\")\n",
    "\n",
    "last_div_tag = soup.find(\"div\", \"container main-page\")\n",
    "soup.find(\"h1\").string\n",
    "#for string in last_div_tag.stripped_strings:\n",
    "#    print(repr(string))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "3dd14882",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"Intro (Skit)\" lyrics'"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titleText = soup.find(\"h1\").string\n",
    "try:\n",
    "     songTitle = re.search('\\'\"(.+?) lyrics', titleText).group(1)\n",
    "except AttributeError:\n",
    "    pass\n",
    "#<div class=\"div-share\">\n",
    "#                  <h1>\"Intro (Skit)\" lyrics</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c394f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Total run time was {round((time.time() - start)/3600,2)} hours.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "054cf14b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Evaluation\n",
    "\n",
    "This assignment asks you to pull data from the Twitter API and scrape www.AZLyrics.com.  After you have finished the above sections , run all the cells in this notebook. Print this to PDF and submit it, per the instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217c2b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple word extractor from Peter Norvig: https://norvig.com/spell-correct.html\n",
    "def words(text): \n",
    "    return re.findall(r'\\w+', text.lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9290b4c3",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Checking Twitter Data\n",
    "\n",
    "The output from your Twitter API pull should be two files per artist, stored in files with formats like `cher_followers.txt` (a list of all follower IDs you pulled) and `cher_followers_data.txt`. These files should be in a folder named `twitter` within the repository directory. This code summarizes the information at a high level to help the instructor evaluate your work. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2174c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_files = os.listdir(\"twitter\")\n",
    "twitter_files = [f for f in twitter_files if f != \".DS_Store\"]\n",
    "artist_handles = list(set([name.split(\"_\")[0] for name in twitter_files]))\n",
    "\n",
    "print(f\"We see two artist handles: {artist_handles[0]} and {artist_handles[1]}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad545be",
   "metadata": {},
   "outputs": [],
   "source": [
    "for artist in artist_handles :\n",
    "    follower_file = artist + \"_followers.txt\"\n",
    "    follower_data_file = artist + \"_followers_data.txt\"\n",
    "    \n",
    "    ids = open(\"twitter/\" + follower_file,'r').readlines()\n",
    "    \n",
    "    print(f\"We see {len(ids)-1} in your follower file for {artist}, assuming a header row.\")\n",
    "    \n",
    "    with open(\"twitter/\" + follower_data_file,'r') as infile :\n",
    "        \n",
    "        # check the headers\n",
    "        headers = infile.readline().split(\"\\t\")\n",
    "        \n",
    "        print(f\"In the follower data file ({follower_data_file}) for {artist}, we have these columns:\")\n",
    "        print(\" : \".join(headers))\n",
    "        \n",
    "        description_words = []\n",
    "        locations = set()\n",
    "        \n",
    "        \n",
    "        for idx, line in enumerate(infile.readlines()) :\n",
    "            line = line.strip(\"\\n\").split(\"\\t\")\n",
    "            \n",
    "            try : \n",
    "                locations.add(line[3])            \n",
    "                description_words.extend(words(line[6]))\n",
    "            except :\n",
    "                pass\n",
    "    \n",
    "        \n",
    "\n",
    "        print(f\"We have {idx+1} data rows for {artist} in the follower data file.\")\n",
    "\n",
    "        print(f\"For {artist} we have {len(locations)} unique locations.\")\n",
    "\n",
    "        print(f\"For {artist} we have {len(description_words)} words in the descriptions.\")\n",
    "        print(\"Here are the five most common words:\")\n",
    "        print(Counter(description_words).most_common(5))\n",
    "\n",
    "        \n",
    "        print(\"\")\n",
    "        print(\"-\"*40)\n",
    "        print(\"\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37778a1c",
   "metadata": {},
   "source": [
    "## Checking Lyrics \n",
    "\n",
    "The output from your lyrics scrape should be stored in files located in this path from the directory:\n",
    "`/lyrics/[Artist Name]/[filename from URL]`. This code summarizes the information at a high level to help the instructor evaluate your work. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bccac29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "artist_folders = os.listdir(\"lyrics/\")\n",
    "artist_folders = [f for f in artist_folders if os.path.isdir(\"lyrics/\" + f)]\n",
    "\n",
    "for artist in artist_folders : \n",
    "    artist_files = os.listdir(\"lyrics/\" + artist)\n",
    "    artist_files = [f for f in artist_files if 'txt' in f or 'csv' in f or 'tsv' in f]\n",
    "\n",
    "    print(f\"For {artist} we have {len(artist_files)} files.\")\n",
    "\n",
    "    artist_words = []\n",
    "\n",
    "    for f_name in artist_files : \n",
    "        with open(\"lyrics/\" + artist + \"/\" + f_name) as infile : \n",
    "            artist_words.extend(words(infile.read()))\n",
    "\n",
    "            \n",
    "    print(f\"For {artist} we have roughly {len(artist_words)} words, {len(set(artist_words))} are unique.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
