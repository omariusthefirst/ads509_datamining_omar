{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f79baf9",
   "metadata": {},
   "source": [
    "# Omar Elfeky\n",
    "# ADS 509 Assignment 2.1: Tokenization, Normalization, Descriptive Statistics \n",
    "\n",
    "This notebook holds Assignment 2.1 for Module 2 in ADS 509, Applied Text Mining. Work through this notebook, writing code and answering questions where required. \n",
    "\n",
    "In the previous assignment you put together Twitter data and lyrics data on two artists. In this assignment we explore some of the textual features of those data sets. If, for some reason, you did not complete that previous assignment, data to use for this assignment can be found in the assignment materials section of Blackboard. \n",
    "\n",
    "This assignment asks you to write a short function to calculate some descriptive statistics on a piece of text. Then you are asked to find some interesting and unique statistics on your corpora. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae8e2e1",
   "metadata": {},
   "source": [
    "## General Assignment Instructions\n",
    "\n",
    "These instructions are included in every assignment, to remind you of the coding standards for the class. Feel free to delete this cell after reading it. \n",
    "\n",
    "One sign of mature code is conforming to a style guide. We recommend the [Google Python Style Guide](https://google.github.io/styleguide/pyguide.html). If you use a different style guide, please include a cell with a link. \n",
    "\n",
    "Your code should be relatively easy-to-read, sensibly commented, and clean. Writing code is a messy process, so please be sure to edit your final submission. Remove any cells that are not needed or parts of cells that contain unnecessary code. Remove inessential `import` statements and make sure that all such statements are moved into the designated cell. \n",
    "\n",
    "Make use of non-code cells for written commentary. These cells should be grammatical and clearly written. In some of these cells you will have questions to answer. The questions will be marked by a \"Q:\" and will have a corresponding \"A:\" spot for you. *Make sure to answer every question marked with a `Q:` for full credit.* \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2d096b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import emoji\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#needed to run once\n",
    "#import nltk\n",
    "#nltk.download()\n",
    "from collections import Counter, defaultdict\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "from collections import Counter\n",
    "sw = stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b555ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lexicalrichness import LexicalRichness\n",
    "import csv\n",
    "import regex\n",
    "#default is 1e6\n",
    "#jupyter notebook --NotebookApp.iopub_data_rate_limit=1.0e10\n",
    "#for my desktop\n",
    "os.environ['NUMEXPR_MAX_THREADS'] = '24'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "923b5a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change `data_location` to the location of the folder on your machine.\n",
    "data_location = \"/Users/elfek/datamining/\"\n",
    "\n",
    "# These subfolders should still work if you correctly stored the \n",
    "# data from the Module 1 assignment\n",
    "twitter_folder = \"twitter/\"\n",
    "lyrics_folder = \"lyrics/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06522af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def descriptive_stats(tokens, num_tokens = 5, verbose=True) :\n",
    "    \"\"\"\n",
    "        Given a list of tokens, print number of tokens, number of unique tokens, \n",
    "        number of characters, lexical diversity (https://en.wikipedia.org/wiki/Lexical_diversity), \n",
    "        and num_tokens most common tokens. Return a list with the number of tokens, number\n",
    "        of unique tokens, lexical diversity, and number of characters. \n",
    "    \n",
    "    \"\"\"\n",
    "    from collections import Counter\n",
    "    # Fill in the correct values here. \n",
    "    num_tokens = len(tokens)\n",
    "    num_unique_tokens = len(set(tokens))\n",
    "    lexical_diversity = 0.0\n",
    "    # Return Measure of Textual Lexical Diversity (MTLD).\n",
    "    space = \" \"\n",
    "    text = space.join( tokens )\n",
    "    lex = LexicalRichness(text)\n",
    "    #len(tokens)\n",
    "    lexical_diversity = lex.hdd(draws=13) #lex.mtld(threshold=0.69) #lex.Herdan #lex.Summer \n",
    "    num_characters = 0\n",
    "    for token in tokens:\n",
    "        num_characters = num_characters + len(token)\n",
    "\n",
    "    if verbose :        \n",
    "        print(f\"There are {num_tokens} tokens in the data.\")\n",
    "        print(f\"There are {num_unique_tokens} unique tokens in the data.\")\n",
    "        print(f\"There are {num_characters} characters in the data.\")\n",
    "        print(f\"The lexical diversity is {lexical_diversity:.3f} in the data.\")\n",
    "        # print the five most common tokens\n",
    "        # Pass the split_it list to instance of Counter class.\n",
    "        Counter = Counter(tokens)\n",
    "        # most_common() produces k frequently encountered\n",
    "        # input values and their respective counts.\n",
    "        most_occur = Counter.most_common(5)\n",
    "        print(most_occur)\n",
    "  \n",
    "    return([num_tokens, num_unique_tokens,\n",
    "            lexical_diversity,\n",
    "            num_characters])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59dcf058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 13 tokens in the data.\n",
      "There are 9 unique tokens in the data.\n",
      "There are 55 characters in the data.\n",
      "The lexical diversity is 0.692 in the data.\n",
      "[('text', 3), ('here', 2), ('example', 2), ('is', 1), ('some', 1)]\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"here is some example text with other example text here in this text\"\"\".split()\n",
    "#text\n",
    "assert(descriptive_stats(text, verbose=True)[0] == 13)\n",
    "assert(descriptive_stats(text, verbose=False)[1] == 9)\n",
    "assert(abs(descriptive_stats(text, verbose=False)[2] - 0.69) < 0.02)\n",
    "assert(descriptive_stats(text, verbose=False)[3] == 55)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e7e1a2",
   "metadata": {},
   "source": [
    "Q: Why is it beneficial to use assertion statements in your code? \n",
    "\n",
    "A: Assertion Statements help in debugging code. It allows you to test parts of code at known states."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3bf93e",
   "metadata": {},
   "source": [
    "## Data Input\n",
    "\n",
    "Now read in each of the corpora. For the lyrics data, it may be convenient to store the entire contents of the file to make it easier to inspect the titles individually, as you'll do in the last part of the assignment. In the solution, I stored the lyrics data in a dictionary with two dimensions of keys: artist and song. The value was the file contents. A data frame would work equally well. \n",
    "\n",
    "For the Twitter data, we only need the description field for this assignment. Feel free all the descriptions read it into a data structure. In the solution, I stored the descriptions as a dictionary of lists, with the key being the artist. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37d70801",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the lyrics data\n",
    "lyricsDictionary = {}\n",
    "songTitlesCher = []\n",
    "songTitlesRobyn = []\n",
    "#reading the file\n",
    "os.chdir(r\"C:\\Users\\elfek\\datamining\\lyrics\")\n",
    "for filename in os.listdir(\"cher\"):\n",
    "    with open(os.path.join(\"cher\", filename), 'r') as f:\n",
    "        songLyrics = f.read()\n",
    "        songTitle = songLyrics.split('\\n', 1)[0]\n",
    "        songTitlesCher.append(songTitle)\n",
    "        #print(songTitle)\n",
    "        artist = \"Cher\"\n",
    "        key = (songTitle.replace(\"\\\"\", \"\"), artist)\n",
    "        lyricsDictionary[key] = songLyrics\n",
    "\n",
    "        \n",
    "os.chdir(r\"C:\\Users\\elfek\\datamining\\lyrics\")\n",
    "for filename in os.listdir(\"robyn\"):\n",
    "    with open(os.path.join(\"robyn\", filename), 'r') as f:\n",
    "        songLyrics = f.read()\n",
    "        songTitle = songLyrics.split('\\n', 1)[0]\n",
    "        #print(songTitle)\n",
    "        songTitlesRobyn.append(songTitle)\n",
    "        artist = \"Robyn\"\n",
    "        key = (songTitle, artist)\n",
    "        lyricsDictionary[key] = songLyrics\n",
    "        \n",
    "\n",
    "    \n",
    "#tests\n",
    "#print(lyricsDictionary[('Again','Cher')])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "debcac5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the twitter data\n",
    "# For the Twitter data, we only need the description field for this assignment. \n",
    "# Feel free all the descriptions read it into a data structure. In the solution,\n",
    "# I stored the descriptions as a dictionary of lists, with the key being the artist. \n",
    "  \n",
    "# read text file into pandas DataFrame and\n",
    "os.chdir(r\"C:\\Users\\elfek\\datamining\\twitter\")\n",
    "\n",
    "data = open(r\"cher_followers_data.txt\", encoding=\"utf8\").readlines()\n",
    "\n",
    "#descriptionListCher = \"\"\n",
    "descriptionCher = []\n",
    "for dataLine in data:\n",
    "    line = dataLine.split(\"\\t\")\n",
    "    count=0\n",
    "    for column in line:\n",
    "        count += 1\n",
    "        if (count == 7):\n",
    "            if (column != '\\n'):\n",
    "                #descriptionListCher += column #\n",
    "                descriptionCher.append(column)\n",
    "\n",
    "#remove the title line\n",
    "#descriptionCher = descriptionCher[1:-1]\n",
    "\n",
    "data = open(r\"robynkonichiwa_followers_data.txt\", encoding=\"utf8\").readlines()\n",
    "\n",
    "#descriptionListRobyn = \"\"\n",
    "descriptionRobyn = []\n",
    "for dataLine in data:\n",
    "    line = dataLine.split(\"\\t\")\n",
    "    count=0\n",
    "    for column in line:\n",
    "        count += 1\n",
    "        #skip the unnecessary columns\n",
    "        if (count == 7):\n",
    "            if (column != '\\n'):\n",
    "                #descriptionListRobyn += column # \n",
    "                descriptionRobyn.append(column)\n",
    "\n",
    "#remove the title line\n",
    "#descriptionRobyn = descriptionRobyn[1:-1]\n",
    "  \n",
    "#remove the first 6 words\n",
    "#re.sub(r'^((?:\\w+\\W+){6})', '', data[i])\n",
    "\n",
    "# Remove Special Characters from a String \n",
    "#new_text = re.sub(r\"[^a-zA-Z0-9 ]\", \"\", data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5f3b12",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "\n",
    "Now clean and tokenize your data. Remove punctuation chacters (available in the `punctuation` object in the `string` library), split on whitespace, fold to lowercase, and remove stopwords. Store your cleaned data, which must be accessible as an interable for `descriptive_stats`, in new objects or in new columns in your data frame. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "71c73d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuation = set(punctuation) # speeds up comparison\n",
    "\n",
    "# can't remove hastags #needhashtags\n",
    "#string.replace(\"#\", \"\")\n",
    "\n",
    "#for testing\n",
    "#print(punctuation)\n",
    "\n",
    "#lol the stop words need to be cleaned from punctuation :/\n",
    "for i in range(len(sw)):\n",
    "    for char in sw[i]:\n",
    "        if char in punctuation:\n",
    "            #print (word)\n",
    "            sw[i] = sw[i].replace(char, '')\n",
    "\n",
    "#for testing           \n",
    "#print(sw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b327033a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create your clean lyrics data here\n",
    "# Removing punctuations in string\n",
    "# lyricsCher = \"\"\n",
    "# lyricsRobyn = \"\"\n",
    "#temp = lyricsDictionary.copy().items()\n",
    "for key, value in lyricsDictionary.items():\n",
    "    for ele in value:\n",
    "        if ele in punctuation:\n",
    "            value = value.replace(ele, \"\")\n",
    "            lyricsDictionary[key] = value.casefold()\n",
    "        else:\n",
    "            lyricsDictionary[key] = value.casefold()\n",
    "            #print(value)\n",
    "\n",
    "def remove_stopwords(data):\n",
    "    output_array=[]\n",
    "    for sentence in data:\n",
    "        temp_list=[]\n",
    "        for word in sentence.split():\n",
    "            if word.lower() not in sw:\n",
    "                temp_list.append(word)\n",
    "        output_array.append(' '.join(temp_list))\n",
    "    return output_array   \n",
    "\n",
    "cleanLyricsDictionary = {}\n",
    "for key, value in lyricsDictionary.items():\n",
    "    for ele in value:\n",
    "        cleanLyricsDictionary[key] = list(filter(None, remove_stopwords(value.split())))#remove_stopwords(value.split())\n",
    "        \n",
    "#for testing\n",
    "#print(lyricsDictionary[('Again','Cher')])\n",
    "#print(cleanLyricsDictionary[('Again','Cher')])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "99f690b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "lyricsTokenizedRobyn = []\n",
    "for i in range(len(songTitlesRobyn)): \n",
    "    lyricsTokenizedRobyn.extend(cleanLyricsDictionary[songTitlesRobyn[i],'Robyn'])\n",
    "lyricsTokenizedCher = []\n",
    "for i in range(len(songTitlesCher)): \n",
    "    lyricsTokenizedCher.extend(cleanLyricsDictionary[songTitlesCher[i][1:-1],'Cher'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "34be2fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "uncleanDescriptionCher = descriptionCher.copy()\n",
    "uncleanDescriptionRobyn = descriptionRobyn.copy()\n",
    "\n",
    "for i in range(len(descriptionCher)): \n",
    "    for ele in descriptionCher[i]:\n",
    "        if ele in punctuation:\n",
    "            descriptionCher[i] = descriptionCher[i].replace(ele, \"\")\n",
    "    descriptionCher[i] = descriptionCher[i].casefold()\n",
    "            \n",
    "for i in range(len(descriptionRobyn)):\n",
    "    for ele in descriptionRobyn[i]:\n",
    "        if ele in punctuation:\n",
    "            descriptionRobyn[i] = descriptionRobyn[i].replace(ele, \"\")\n",
    "    descriptionRobyn[i] = descriptionRobyn[i].casefold()\n",
    "\n",
    "descriptionTokenizedCher = []\n",
    "for i in range(len(descriptionCher)): \n",
    "    descriptionTokenizedCher.extend(list(filter(None, remove_stopwords(descriptionCher[i].split()))))\n",
    "\n",
    "\n",
    "descriptionTokenizedRobyn = []\n",
    "for i in range(len(descriptionRobyn)): \n",
    "    descriptionTokenizedRobyn.extend(list(filter(None, remove_stopwords(descriptionRobyn[i].split()))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2dd0179",
   "metadata": {},
   "source": [
    "## Basic Descriptive Statistics\n",
    "\n",
    "Call your `descriptive_stats` function on both your lyrics data and your twitter data and for both artists (four total calls). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f0bbedd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The description stats for Cher's followers' twitter descriptions: \n",
      "\n",
      "There are 15604562 tokens in the data.\n",
      "There are 1517640 unique tokens in the data.\n",
      "There are 92659618 characters in the data.\n",
      "The lexical diversity is 0.995 in the data.\n",
      "[('love', 214576), ('im', 139098), ('life', 122980), ('music', 88177), ('de', 72974)]\n",
      "\n",
      "\n",
      "The description stats for Cher's lyrics: \n",
      "\n",
      "There are 34605 tokens in the data.\n",
      "There are 3682 unique tokens in the data.\n",
      "There are 166607 characters in the data.\n",
      "The lexical diversity is 0.981 in the data.\n",
      "[('love', 995), ('im', 515), ('know', 489), ('time', 320), ('baby', 318)]\n",
      "\n",
      "\n",
      "The description stats for Robyn's followers' twitter descriptions: \n",
      "\n",
      "There are 1490474 tokens in the data.\n",
      "There are 252708 unique tokens in the data.\n",
      "There are 9105295 characters in the data.\n",
      "The lexical diversity is 0.996 in the data.\n",
      "[('music', 15147), ('love', 11677), ('im', 9051), ('och', 7922), ('life', 7383)]\n",
      "\n",
      "\n",
      "The description stats for Robyn's lyrics: \n",
      "\n",
      "There are 14608 tokens in the data.\n",
      "There are 2139 unique tokens in the data.\n",
      "There are 71248 characters in the data.\n",
      "The lexical diversity is 0.975 in the data.\n",
      "[('know', 308), ('im', 299), ('love', 275), ('got', 251), ('like', 232)]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# calls to descriptive_stats here\n",
    "print(\"The description stats for Cher's followers' twitter descriptions: \\n\")\n",
    "descriptive_stats(descriptionTokenizedCher)\n",
    "print(\"\\n\")\n",
    "print(\"The description stats for Cher's lyrics: \\n\")\n",
    "descriptive_stats(lyricsTokenizedCher)\n",
    "print(\"\\n\")\n",
    "print(\"The description stats for Robyn's followers' twitter descriptions: \\n\")\n",
    "descriptive_stats(descriptionTokenizedRobyn)\n",
    "print(\"\\n\")\n",
    "print(\"The description stats for Robyn's lyrics: \\n\")\n",
    "descriptive_stats(lyricsTokenizedRobyn)\n",
    "print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46294409",
   "metadata": {},
   "source": [
    "Q: How do you think the \"top 5 words\" would be different if we left stopwords in the data? \n",
    "\n",
    "A: The stopwords would have dominated the charts due to their high occurance and taken ranks 1 through 5.\n",
    "\n",
    "---\n",
    "\n",
    "Q: What were your prior beliefs about the lexical diversity between the artists? Does the difference (or lack thereof) in lexical diversity between the artists conform to your prior beliefs? \n",
    "\n",
    "A: It is very surprising that both artists have very little difference in lexical diversity. Perhaps the lexical diversity metric is sensitive to small differences. Much the same way a Homosapien and Chimpanzee share a high percentage of DNA but that makes a big difference?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d4e1ac1",
   "metadata": {},
   "source": [
    "\n",
    "## Specialty Statistics\n",
    "\n",
    "The descriptive statistics we have calculated are quite generic. You will now calculate a handful of statistics tailored to these data.\n",
    "\n",
    "1. Ten most common emojis by artist in the twitter descriptions.\n",
    "1. Ten most common hashtags by artist in the twitter descriptions.\n",
    "1. Five most common words in song titles by artist. \n",
    "1. For each artist, a histogram of song lengths (in terms of number of tokens) \n",
    "\n",
    "We can use the `emoji` library to help us identify emojis and you have been given a function to help you.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "753a5a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_emoji(s):\n",
    "    return(s in emoji.UNICODE_EMOJI['en'])\n",
    "\n",
    "assert(is_emoji(\"â¤ï¸\"))\n",
    "assert(not is_emoji(\":-)\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "986fc4c0",
   "metadata": {},
   "source": [
    "### Emojis ðŸ˜\n",
    "\n",
    "What are the ten most common emojis by artist in the twitter descriptions? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2b4a633f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('â¤', 79223), ('ðŸŒˆ', 47549), ('â™¥', 33978), ('ðŸ³', 33412), ('âœ¨', 29468), ('ðŸ’™', 21379), ('ðŸ»', 20930), ('ðŸŒŠ', 20223), ('âœŒ', 16773), ('ðŸ’œ', 16550)]\n",
      "[('â¤', 4783), ('ðŸŒˆ', 4685), ('ðŸ³', 3528), ('â™¥', 3103), ('âœ¨', 2223), ('ðŸ»', 1495), ('âœŒ', 1189), ('ðŸ¼', 1139), ('â™€', 836), ('ðŸ’™', 809)]\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "\n",
    "def extract_emojis(list2):\n",
    "    emoji_list = []\n",
    "    list_real = []\n",
    "    for word in list2:\n",
    "        temp = re.findall(r'[^\\w\\s,]', word) #doesn't exactly find emojis since it capture weird non-english chars\n",
    "        emoji_list.extend(temp)\n",
    "    for s in emoji_list:\n",
    "        if (s in emoji.UNICODE_EMOJI['en']): \n",
    "            list_real.extend(s)\n",
    "    return list_real\n",
    "\n",
    "countsRobyn = Counter(extract_emojis(descriptionTokenizedCher))\n",
    "countsCher = Counter(extract_emojis(descriptionTokenizedRobyn))\n",
    "#countsRobyn = Counter(list(filter(None, extract_emojis(descriptionTokenizedCher))))\n",
    "#countsCher = Counter(list(filter(None, extract_emojis(descriptionTokenizedRobyn))))\n",
    "print(countsRobyn.most_common(10))\n",
    "print(countsCher.most_common(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab9b770",
   "metadata": {},
   "source": [
    "### Hashtags\n",
    "\n",
    "What are the ten most common hashtags by artist in the twitter descriptions? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "07c396f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most common hashtags for Cher are:\n",
      "[('resist', 11657), ('blm', 10466), ('blacklivesmatter', 8154), ('theresistance', 3508), ('fbr', 3419), ('resistance', 3061), ('1', 2627), ('voteblue', 2304), ('lgbtq', 2074), ('music', 1602)]\n",
      "\n",
      "\n",
      "The most common hashtags for Robyn are:\n",
      "[('blacklivesmatter', 601), ('blm', 362), ('music', 306), ('1', 199), ('teamfollowback', 135), ('edm', 111), ('lgbtq', 89), ('resist', 86), ('travel', 73), ('art', 72)]\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "\n",
    "#descriptionRobyn\n",
    "#descriptionCher\n",
    "tagsCher = []\n",
    "tagsRobyn = []\n",
    "#re.findall(r\"#(\\w+)\", s)\n",
    "for word in uncleanDescriptionCher:\n",
    "    tagsCher.extend(re.findall(r\"#(\\w+)\", word.casefold()))\n",
    "for word in uncleanDescriptionRobyn:\n",
    "    tagsRobyn.extend(re.findall(r\"#(\\w+)\", word.casefold()))\n",
    "    \n",
    "print(\"The most common hashtags for Cher are:\")    \n",
    "print(Counter(tagsCher).most_common(10))\n",
    "print(\"\\n\")\n",
    "print(\"The most common hashtags for Robyn are:\")\n",
    "\n",
    "print(Counter(tagsRobyn).most_common(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d10f21d5",
   "metadata": {},
   "source": [
    "### Song Titles\n",
    "\n",
    "What are the five most common words in song titles by artist? The song titles should be on the first line of the lyrics pages, so if you have kept the raw file contents around, you will not need to re-read the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ceed237a",
   "metadata": {},
   "outputs": [],
   "source": [
    "stRobyn = songTitlesRobyn.copy()\n",
    "stCher = songTitlesCher.copy()\n",
    "for i in range(len(songTitlesCher)):\n",
    "    for ele in songTitlesCher[i]:\n",
    "        if ele in punctuation:\n",
    "            songTitlesCher[i] = songTitlesCher[i].replace(ele, \"\").casefold()\n",
    "        else:\n",
    "            songTitlesCher[i] = songTitlesCher[i].casefold()\n",
    "            #print(value)\n",
    "\n",
    "\n",
    "for i in range(len(songTitlesRobyn)):\n",
    "    for ele in songTitlesRobyn[i]:\n",
    "        if ele in punctuation:\n",
    "            songTitlesRobyn[i] = songTitlesRobyn[i].replace(ele, \"\").casefold()\n",
    "        else:\n",
    "            songTitlesRobyn[i] = songTitlesRobyn[i].casefold()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bb69b36b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('love', 38), ('man', 12), ('song', 11), ('come', 7), ('one', 7)]\n",
      "[('love', 6), ('u', 4), ('thing', 3), ('girl', 3), ('tell', 3)]\n"
     ]
    }
   ],
   "source": [
    "     \n",
    "songTitlesTokenizedCher = []\n",
    "for song in songTitlesCher: \n",
    "    songTitlesTokenizedCher.extend(remove_stopwords(song.split()))\n",
    "    \n",
    "songTitlesTokenizedRobyn = []\n",
    "for song in songTitlesRobyn: \n",
    "    songTitlesTokenizedRobyn.extend(remove_stopwords(song.split()))\n",
    "    \n",
    "print( Counter(songTitlesTokenizedCher).most_common(6)[1:] )\n",
    "print( Counter(songTitlesTokenizedRobyn).most_common(6)[1:] )\n",
    "#songTitlesTokenizedCher\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd4fd71",
   "metadata": {},
   "source": [
    "### Song Lengths\n",
    "\n",
    "For each artist, a histogram of song lengths (in terms of number of tokens). If you put the song lengths in a data frame with an artist column, matplotlib will make the plotting quite easy. An example is given to help you out. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "805a1e52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "artist\n",
       "Artist 1    AxesSubplot(0.125,0.125;0.775x0.755)\n",
       "Artist 2    AxesSubplot(0.125,0.125;0.775x0.755)\n",
       "Name: length, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_replicates = 1000\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"artist\" : ['Artist 1'] * num_replicates + ['Artist 2']*num_replicates,\n",
    "    \"length\" : np.concatenate((np.random.poisson(125,num_replicates),np.random.poisson(150,num_replicates)))\n",
    "})\n",
    "\n",
    "df.groupby('artist')['length'].plot(kind=\"hist\",density=True,alpha=0.5,legend=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fde9ebb",
   "metadata": {},
   "source": [
    "Since the lyrics may be stored with carriage returns or tabs, it may be useful to have a function that can collapse whitespace, using regular expressions, and be used for splitting. \n",
    "\n",
    "Q: What does the regular expression `'\\s+'` match on? \n",
    "\n",
    "A: The regular expression matches on any combinacion and repetition of whitespace characters such as space, tab, carriage return, new line, vertical tab, form feed characterd.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f0e34516",
   "metadata": {},
   "outputs": [],
   "source": [
    "collapse_whitespace = re.compile(r'\\s+')\n",
    "\n",
    "def tokenize_lyrics(lyric) : \n",
    "    \"\"\"strip and split on whitespace\"\"\"\n",
    "    return([item.lower() for item in collapse_whitespace.split(lyric)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2294c440",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your lyric length comparison chart here. \n",
    "\n",
    "\n",
    "lyricLengthCher = []\n",
    "lyricLengthRobyn = []\n",
    "for i in range(len(songTitlesRobyn)): \n",
    "    lyricLengthRobyn.append( len( (cleanLyricsDictionary[stRobyn[i],'Robyn']) ))\n",
    "                            \n",
    "for i in range(len(songTitlesCher)): \n",
    "    lyricLengthCher.append( len( (cleanLyricsDictionary[stCher[i][1:-1],'Cher']) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "441e9e26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "artist\n",
       "Cher     AxesSubplot(0.125,0.125;0.775x0.755)\n",
       "Robyn    AxesSubplot(0.125,0.125;0.775x0.755)\n",
       "Name: length, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.DataFrame({\n",
    "    \"artist\" : ['Cher'] * len(songTitlesCher) + ['Robyn']*len(songTitlesRobyn),\n",
    "    \"length\" : np.concatenate((np.array(lyricLengthCher), np.array(lyricLengthRobyn)))\n",
    "})\n",
    "\n",
    "df.groupby('artist')['length'].plot(kind=\"hist\",density=True,alpha=0.5,legend=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
